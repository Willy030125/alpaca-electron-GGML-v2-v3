<h1 align="center">
<sub>
<img src="https://raw.githubusercontent.com/ItsPi3141/alpaca-electron/main/icon/alpaca-chat-logo.png?raw=true" height=144>
</sub>
<br>
Alpaca Electron
</h1>
<br>
<p align="center">
  <a href="https://nodejs.org">
    <img src="https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&logo=node.js&logoColor=white">
  </a>
  <a href="https://www.electronjs.org/">
    <img src="https://img.shields.io/badge/Electron-191970?style=for-the-badge&logo=Electron&logoColor=white">
  </a>
  <a href="https://github.com/antimatter15/alpaca.cpp/">
    <img src="https://img.shields.io/badge/Alpaca.cpp-%2300599C.svg?style=for-the-badge&logo=c%2B%2B&logoColor=white">
  </a>
</p>
<p align="center">
  <a href="https://discord.gg/W7xwHpPWth">
    <img src="https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&logo=discord&logoColor=white">
  </a>
</p>
<p align="center"><i>Alpaca Electron is built from the ground-up to be the easiest way to chat with the alpaca AI models. No command line or compiling needed!</i></p>
<hr>

## üìÉ Highlights

This updated Alpaca-Electron is designed for GGML v2 and v3. Also in this build there's web-search integration albeit much slower to summarize it.

- Alpaca Electron GGML v2: [Download](https://github.com/Willy030125/alpaca-electron-GGML-v2-v3/releases/download/v1.0.6/Alpaca.Electron.v1.0.6.x64-win.GGMLv2.zip)
- Alpaca Electron GGML v3: [Download](https://github.com/Willy030125/alpaca-electron-GGML-v2-v3/releases/download/v1.0.6/Alpaca.Electron.v1.0.6.x64-win.GGMLv3.zip)

## üöÄ Model download
Example of GGMLv2:
- https://huggingface.co/eachadea/ggml-gpt4-x-vicuna-13b/blob/main/ggml-gpt4-x-vicuna-13b-q4_0.bin

Example of GGMLv3:
- https://huggingface.co/TheBloke/gpt4-x-vicuna-13B-GGML/blob/main/gpt4-x-vicuna-13B.ggmlv3.q4_0.bin
- https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/blob/main/llama-2-13b-chat.ggmlv3.q4_0.bin

## üéû Preview

![Demonstration](https://raw.githubusercontent.com/Willy030125/alpaca-electron-GGML-v2-v3/main/1.jpg)

![Demonstration](https://raw.githubusercontent.com/Willy030125/alpaca-electron-GGML-v2-v3/main/2.jpg)


## üë®‚Äçüíª Credits

Special thanks to [@ItsPi3141](https://github.com/ItsPi3141/alpaca-electron) for creating Alpaca-Electron, [@antimatter15](https://github.com/antimatter15/alpaca.cpp) for creating alpaca.cpp and to [@ggerganov](https://github.com/ggerganov/llama.cpp) for creating llama.cpp, the backbones behind alpaca.cpp. Finally, credits go to Meta and Stanford for creating the LLaMA and Alpaca models, respectively.
